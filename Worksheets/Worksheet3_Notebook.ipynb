{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbconvert": {
     "hide_code": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Simpson's rule to compute\n",
    "$$\n",
    "  \\int_0^{\\pi/2} \\cos (x) \\, dx\n",
    "$$\n",
    "using 3 points (so $h = \\pi/4$) and 5 points (so $h = \\pi/8$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "### Answer Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "The exact solution is, of course, 1.\n",
    "\n",
    "Simpson’s rule (composite version) is\n",
    "$$\n",
    "  I = \\frac{h}{3} \\left[ f(a) + f(b) + 2 \\sum_{j = 1}^{N/2 - 1} f(x_{2 j}) + 4 \\sum_{j = 1}^{N/2} f(x_{2 j-1})  \\right]\n",
    "$$\n",
    "where we are using $N + 1$ points with $N$ even, with $x_0 = a, x_N = b$, equally spaced with grid spacing $h = (b − a)/N$.\n",
    "\n",
    "With 3 points we have $N = 2$ and $h = (\\pi/2)/2 = \\pi/4$, and so we have nodes and samples given by\n",
    "$$\n",
    "  \\begin{array}{c|c|c}\n",
    "    i & x_i & f(x_i) \\\\ \\hline\n",
    "    0 & 0 & 1 \\\\\n",
    "    1 & \\pi/4 & 1 / \\sqrt{2} \\\\\n",
    "    2 & \\pi/2 & 0\n",
    "  \\end{array}\n",
    "$$\n",
    "Using Simpson's rule we then get\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  I &= \\frac{h}{3} \\left[ f_0 + f_2 + 4 f_1 \\right] \\\\\n",
    "    & = \\frac{\\pi}{12} \\left[ 1 + 2 \\sqrt{2} \\right] \\\\\n",
    "    & \\approx 1.0023. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "With 5 points we have $N = 4$ and $h = (\\pi/2)/4 = \\pi/8$, and so we have nodes and samples given by\n",
    "$$\n",
    "  \\begin{array}{c|c|c}\n",
    "    i & x_i & f(x_i) \\\\ \\hline\n",
    "    0 & 0 & 1 \\\\\n",
    "    1 & \\pi/8 & \\cos ( \\pi / 8 ) \\approx 0.9239 \\\\\n",
    "    2 & \\pi/4 & 1 / \\sqrt{2} \\\\\n",
    "    3 & 3\\pi/8 & \\cos ( 3 \\pi / 8 ) \\approx 0.9239 \\\\\n",
    "    4 & \\pi/2 & 0\n",
    "  \\end{array}\n",
    "$$\n",
    "Using Simpson's rule we then get\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  I &= \\frac{h}{3} \\left[ f_0 + f_4 + 4 (f_1 + f_3) + 2 f_2 \\right] \\\\\n",
    "    & = \\frac{\\pi}{24} \\left[ 1 + 4 \\left( \\cos ( \\pi / 8 ) + \\cos ( 3 \\pi / 8 ) \\right) + \\sqrt{2} \\right] \\\\\n",
    "    & \\approx 1.00013. \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Richardson extrapolation to the result above; does the answer improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "### Answer Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "Simpson's rule has order of accuracy 4. We note that we have just computed the result using 3 ($N = 2$) and 5 ($N = 4$) points. Richardson extrapolation gives the result\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  R_4 &= \\frac{2^4 I_{N=4} - I_{N=2}}{2^4 - 1} \\\\\n",
    "      &\\approx 0.999992.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We note that the error has gone from $2.3 \\times 10^{−3}$ for $I_{N=2}$ to $1.3 \\times 10^{−4}$ for $I_{N=4}$ and now to $8.4 \\times 10^{−6}$ for the Richardson extrapolation $R_4$, a good improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State the rate of convergence of the trapezoidal rule and Simpson’s rule, and sketch (or explain in words) the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "### Answer Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "For the trapezoidal rule the error converges as $h^2$. For Simpson’s rule the error converges as $h^4$.\n",
    "\n",
    "In both cases the proof takes a similar path. Consider the quadrature over a single subinterval. Taylor series expand the quadrature rule about a suitable point $x_j$ (left edge for trapezoidal rule, centre for Simpson’s rule) to get an expression for the quadrature of the interval in terms of $h$ and the function $f$ and its derivatives as evaluated at $x_j$.\n",
    "\n",
    "Next write down the anti-derivative $F(t)$ of $f$ for the interval as a function of the width of the interval $t$. This, when evaluated at $t = h$, is the exact solution for the quadrature of the subinterval. Taylor series expand $F$ about $t = 0$ to get an expression for the exact result in terms of $h$ and the function $f$ and its derivatives as evaluated at $x_j$.\n",
    "\n",
    "By comparing the two expressions we have a bound on the error in terms of $h$ and derivatives of $f$. By summing over all intervals (note that at this stage we lose a power of $h$ as we have $N$ subintervals with $N \\propto h^{−1}$) we can bound the global error in terms of $h$ and the maximum value of a derivative of $f$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain in words adaptive and Gaussian quadrature, in particular the aims of each and the times when one or the other is more useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "### Answer Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "Adaptive quadrature uses any standard quadrature method and some error estimator, such as Richardson extrapolation, to place additional nodes wherever required to ensure that the error is less than some desired tolerance. Each subinterval is tested to ensure that its (appropriately weighted) contribution to the total error is sufficiently small. If it is not, the subinterval is further subdivided by introducing more nodes in a fashion appropriate for the quadrature method used. This is a straightforward way of getting high accuracy for low computational cost using standard quadrature algorithms.\n",
    "\n",
    "Gaussian quadrature aims to get the best result for a *generic* function by allowing both the choice of nodes and weights to vary. The location of the nodes and the value of the weights is given by ensuring that the quadrature is exact for as many polynomials as possible; i.e., if we have $N$ nodes (and hence $N$ weights) we should be able to exactly integrate $x^s$ for $0 \\le s \\le 2 N − 1$. By introducing a weighting function we can also deal with integrands that are (mildly) singular at the boundaries of the domain, or unbounded domains. Provided the function can be evaluated anywhere this is an effective way of getting high accuracy with few function evaluations for most functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show how the speed of convergence of a nonlinear root finding method depends on the derivatives of the map $g(x)$ near the fixed point $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "### Answer Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "We assume we are constructing an iterative sequence $x_n$ where $x_{n+1} = g(x_n)$, and that the error at step $n$ is $e_n = x_n − s$. Then if we assume that the step $x_{n+1}$ is sufficiently close to the root $s$ then we can write\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  e_{n+1} &= x_{n+1} − s \\\\\n",
    "  & = g(x_n) − g(s) \n",
    "\\end{aligned}\n",
    "$$\n",
    "which, using the definition of the sequence and the fixed point, gives\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  e_{n+1} & = g(s) (x_n − s) + \\frac{g''(s)}{2!} (x_n − s)^2 + {\\mathcal O} \\left( (x_n − s)^3 \\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "and, by Taylor expanding\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  e_{n+1} & = g(s) e_n + \\frac{g''(s)}{2!} e_n^2 + {\\mathcal O} \\left( e_n^3 \\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Hence if $g(s) = 0$ we have that the error reduces by a constant amount proportional to the derivative at each step. If the derivative does vanish the error at each iteration is proportional to the square of the previous error which leads to faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Newton's method to find the root in $[0, 1]$ of\n",
    "$$\n",
    "  f(x) = \\sin (x) − e^x + 0.9 + x.\n",
    "$$\n",
    "Start from $x_0 = 1/2$ and retain 3 significant figures. Take 3 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "### Answer Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "For Newton's method we have\n",
    "$$\n",
    "  x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}.\n",
    "$$\n",
    "So first we compute the derivative,\n",
    "$$\n",
    "f(x) = \\cos (x) − e^x + 1.\n",
    "$$\n",
    "It follows that the iterative scheme is given by\n",
    "$$\n",
    "  x_{n+1} = x_n − \\frac{ \\sin (x_n) − e^{x_n} + 0.9 + x_n}{\\cos (x_n) − e^{x_n} + 1}.\n",
    "$$\n",
    "\n",
    "We start from $x_0 = 1/2$ and compute with full precision but only retain 3 significant figures for the values of the $x_n$:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  x_1 & = x_0 − \\frac{ \\sin (x_0) − e^{x_0} + 0.9 + x_0}{\\cos (x_0) − e^{x_0} + 1} \\\\\n",
    "      & \\approx -0.508;\n",
    "\\end{aligned}\n",
    "$$\n",
    "retaining 3 s.f. we set $x_1 = −0.508$, and find\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  x_2 & = x_1 − \\frac{ \\sin (x_1) − e^{x_1} + 0.9 + x_1}{\\cos (x_1) − e^{x_1} + 1} \\\\\n",
    "      & \\approx 0.0393;\n",
    "\\end{aligned}\n",
    "$$\n",
    "retaining 3 s.f. we set $x_2 = 0.0393$, and find\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  x_3 & = x_2 − \\frac{ \\sin (x_2) − e^{x_2} + 0.9 + x_2}{\\cos (x_2) − e^{x_2} + 1} \\\\\n",
    "      & \\approx 0.103.\n",
    "\\end{aligned}\n",
    "$$\n",
    "After 5 steps you would see, to 3 s.f., that it has converged to 0.106, so after 3 steps it does quite\n",
    "well; a better approximation to the solution is $0.106022965\\dots$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbconvert": {
     "hide_solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def newton(f, df, x0, tolerance = 1e-10, MaxSteps = 100):\n",
    "    \"\"\"\n",
    "    Implementing Newton's method to solve f(x) = 0, \n",
    "    where df is the derivative of f, \n",
    "    starting from the guess x_0.\n",
    "    \"\"\"\n",
    "    \n",
    "    x = numpy.zeros(MaxSteps)\n",
    "    x[0] = x0\n",
    "    \n",
    "    # Set up the map g\n",
    "    g = lambda x: x - f(x) / df(x)\n",
    "    \n",
    "    for i in range(1, MaxSteps):\n",
    "        x[i] = g(x[i-1])\n",
    "        if (numpy.absolute(f(x[i])) < tolerance):\n",
    "            break\n",
    "    return x[:i+1]\n",
    "\n",
    "def fn_q6(x):\n",
    "    \"\"\"\n",
    "    Simple function defined in question,\n",
    "    f(x) = sin(x) - e^x + 0.9 + x.\n",
    "    \"\"\"\n",
    "    \n",
    "    return numpy.sin(x) - numpy.exp(x) + 0.9 + x\n",
    "\n",
    "def d_fn_q6(x):\n",
    "    \"\"\"\n",
    "    Derivative of simple function defined in question,\n",
    "    f(x) = sin(x) - e^x + 0.9 + x.\n",
    "    \"\"\"\n",
    "    \n",
    "    return numpy.cos(x) - numpy.exp(x) + 1.0\n",
    "\n",
    "\n",
    "x = newton(fn_q6, d_fn_q6, 0.5, tolerance = 1e-15)\n",
    "print(\"The root is approximately {:.5} where f is {:.5}\"\n",
    "      \" after {} steps.\\n\".format(x[-1], fn_q6(x[-1]), len(x)))\n",
    "print(\"The first three steps are {}\\n\".format(x[1:4]))\n",
    "print(\"The fifth step is \", x[5])\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "fig = pyplot.figure(figsize = (12, 8), dpi = 50)\n",
    "pyplot.semilogy(range(len(x)-1), numpy.absolute(x[:-1] - x[-1]), 'kx')\n",
    "pyplot.xlabel('Iteration', size = 16)\n",
    "pyplot.ylabel('$|x_i - x_{final}|$', size = 16)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a single function that, depending on an input argument, computes the integral of an input function $f(x)$ between the input arguments $a, b$, using either\n",
    "\n",
    "1. Simpson's rule, 3 points\n",
    "2. Trapezoidal rule, 3 points\n",
    "3. Gaussian Quadrature, 3 nodes.\n",
    "\n",
    "Test your code on\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  \\int_0^1 \\sin^2 ( \\pi x ) & = \\frac{1}{2}, \\\\\n",
    "  \\int_0^1 e^{-x} \\sinh ( x ) d x & \\approx 0.283833821 \\\\\n",
    "  \\int_0^1 \\frac{1}{\\sqrt{x}} d x & = 2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "Note that there are good reasons for some of the methods to fail on the final test!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "### Answer Coding Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbconvert": {
     "hide_solution": true
    }
   },
   "outputs": [],
   "source": [
    "def integrate(f, a, b, method = 'Simpson'):\n",
    "    \"\"\"\n",
    "    Integrate a given function f over [a, b] using 3 points/nodes using \n",
    "    one of three methods (Simpson, Trapezoidal, Gauss).\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'Simpson':\n",
    "        h = (b - a) / 2.0\n",
    "        I = h / 3.0 * (f(a) + f(b) + 4.0 * f( (a + b) / 2.0 ))\n",
    "    elif method == 'Trapezoidal':\n",
    "        h = (b - a) / 2.0\n",
    "        I = h / 2.0 * (f(a) + f(b) + 2.0 * f( (a + b) / 2.0 ))\n",
    "    elif method == 'Gauss':\n",
    "        nodes = numpy.array([-numpy.sqrt(3.0/5.0), 0.0, \n",
    "                             numpy.sqrt(3.0/5.0)])\n",
    "        weights = numpy.array([5.0/9.0, 8.0/9.0, 5.0/9.0])\n",
    "        # Remap [-1, 1] to the given interval\n",
    "        nodes = (nodes + 1.0) * (b - a) / 2.0 + a\n",
    "        I = 0\n",
    "        for i in range(len(nodes)):\n",
    "            I += weights[i] * f(nodes[i])\n",
    "        # Reweight\n",
    "        I *= (b - a) / 2.0\n",
    "    else:\n",
    "        raise Exception(\"method parameter unknown: must be one of \"\n",
    "                        \"['Simpson', 'Trapezoidal', 'Gauss']\")\n",
    "    \n",
    "    return I\n",
    "\n",
    "def f1(x):\n",
    "    \"\"\"First integrand\"\"\"\n",
    "    \n",
    "    return numpy.sin(numpy.pi * x)**2\n",
    "\n",
    "def f2(x):\n",
    "    \"\"\"Second integrand\"\"\"\n",
    "    \n",
    "    return numpy.exp(-x) * numpy.sinh(x)\n",
    "\n",
    "def f3(x):\n",
    "    \"\"\"Third integrand\"\"\"\n",
    "    \n",
    "    return 1.0 / numpy.sqrt(x)\n",
    "\n",
    "# Now look at the results\n",
    "\n",
    "exact_solutions = [0.5, 0.283833821, 2.0]\n",
    "\n",
    "integrand = 0\n",
    "for i in [f1, f2, f3]:\n",
    "    integrand +=1\n",
    "    for m in ['Simpson', 'Trapezoidal', 'Gauss']:\n",
    "        print(\"For integrand number {} using method {}\\n\"\n",
    "              \"the result is {:.5} (exact solution is {:.5})\\n\"\\\n",
    "              .format(integrand, m, integrate(i, 0, 1, m), \n",
    "                      exact_solutions[integrand-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "The results for the final integral will fail for those methods that evaluate the integral at $x = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the secant method to find the root of\n",
    "$$\n",
    "  f(x) = \\tan (x) - e^{-x}, \\quad x \\in [0, 1].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbconvert": {
     "hide_solution": true
    }
   },
   "source": [
    "### Answer Coding Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbconvert": {
     "hide_solution": true
    }
   },
   "outputs": [],
   "source": [
    "def Secant(f, x0, x1, tolerance = 1e-10, MaxSteps = 100):\n",
    "    \"\"\"\n",
    "    Implement the secant method to find the root of the equation f(x) = 0, \n",
    "    starting from the initial guesses x^{(0,1)} = x0, x1\n",
    "    \"\"\"\n",
    "    \n",
    "    x = numpy.zeros(MaxSteps)\n",
    "    x[0] = x0\n",
    "    x[1] = x1\n",
    "    \n",
    "    # There is no map!\n",
    "    for i in range(2, MaxSteps):\n",
    "        x[i] = x[i-1] - f(x[i-1]) * \\\n",
    "             (x[i-1] - x[i-2]) / (f(x[i-1]) - f(x[i-2]))\n",
    "        if (numpy.absolute(f(x[i])) < tolerance):\n",
    "            break\n",
    "    return x[:i+1]\n",
    "\n",
    "# Now define the function whose root is to be found\n",
    "def fn_q2(x):\n",
    "    \"\"\"\n",
    "    Simple function defined in question, f(x) = tan(x) - exp(-x).\n",
    "    \"\"\"\n",
    "    \n",
    "    return numpy.tan(x) - numpy.exp(-x)\n",
    "\n",
    "\n",
    "x = Secant(fn_q2, 0.0, 1.0)\n",
    "print(\"The root is approximately {:.5} where f is {:.5}\"\n",
    "      \" after {} steps.\\n\".format(x[-1], fn_q2(x[-1]), len(x)))\n",
    "\n",
    "fig = pyplot.figure(figsize = (12, 8), dpi = 50)\n",
    "pyplot.semilogy(range(len(x)-1), numpy.absolute(x[:-1] - x[-1]), 'kx')\n",
    "pyplot.xlabel('Iteration', size = 16)\n",
    "pyplot.ylabel('$|x_i - x_{final}|$', size = 16)\n",
    "\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
